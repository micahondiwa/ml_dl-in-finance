{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Models in TensorFlow: Timing Factors and Smart-Beta Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Goal**: To build a neural network, under a linear model, that aims to predict the future returns of the momentum factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data SOurce**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are gping to take as inputs the returns from a momentum factor. Using these inputs, we will then aim to predict next period momentum factor returns using as inputs past returns. \n",
    "\n",
    "- Data source is Prof. Ken French's Data Library: [Daily returns of 10 Portfolios Formed Daily on Momentum.](https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data_Library/det_10_port_form_pr_12_2_daily.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Timing Momentum with (Linear Regression) Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "route = \"10_Portfolios_Prior_12_2_Daily.CSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lo PRIOR</th>\n",
       "      <th>PRIOR 2</th>\n",
       "      <th>PRIOR 3</th>\n",
       "      <th>PRIOR 4</th>\n",
       "      <th>PRIOR 5</th>\n",
       "      <th>PRIOR 6</th>\n",
       "      <th>PRIOR 7</th>\n",
       "      <th>PRIOR 8</th>\n",
       "      <th>PRIOR 9</th>\n",
       "      <th>Hi PRIOR</th>\n",
       "      <th>Mom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1926-11-03</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926-11-04</th>\n",
       "      <td>0.65</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926-11-05</th>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926-11-06</th>\n",
       "      <td>1.03</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926-11-08</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Lo PRIOR  PRIOR 2  PRIOR 3  PRIOR 4  PRIOR 5  PRIOR 6  PRIOR 7  \\\n",
       "1926-11-03     -0.12     0.60    -0.09     0.30    -0.51    -0.22    -0.12   \n",
       "1926-11-04      0.65     1.82     1.34     0.61     1.01     0.64     0.82   \n",
       "1926-11-05     -0.84    -0.77    -0.22    -0.15    -0.02    -0.02    -0.07   \n",
       "1926-11-06      1.03     0.28     0.24     0.40     0.19     0.64     0.10   \n",
       "1926-11-08     -0.06     0.11     1.78     0.28     0.36     0.23     0.30   \n",
       "\n",
       "            PRIOR 8  PRIOR 9  Hi PRIOR   Mom  \n",
       "1926-11-03     0.50     0.13      1.28  1.40  \n",
       "1926-11-04     0.44     0.48      0.40 -0.25  \n",
       "1926-11-05     0.36     0.20      0.08  0.92  \n",
       "1926-11-06     0.10     0.39     -0.68 -1.71  \n",
       "1926-11-08     1.17     0.58     -0.18 -0.12  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file again with skipped rows\n",
    "df = pd.read_csv(route, index_col=0)\n",
    "# Format the date index\n",
    "df.index = pd.to_datetime(df.index, format=\"%Y%m%d\")\n",
    "# Build the MOM strategy: Long \"Hi PRIOR\" and Short \"Lo PRIOR\"\n",
    "df[\"Mom\"] = df[\"Hi PRIOR\"] - df[\"Lo PRIOR\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Inputs and Outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Ret\"] = df[\"Mom\"]\n",
    "df[\"Ret10_MOMi\"] = df[\"Mom\"].rolling(10).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "df[\"Ret25_MOMi\"] = df[\"Mom\"].rolling(25).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "df[\"Ret60_MOMi\"] = df[\"Mom\"].rolling(60).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "df[\"Ret120_MOMi\"] = df[\"Mom\"].rolling(120).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "df[\"Ret240_MOMi\"] = df[\"Mom\"].rolling(240).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "\n",
    "df[\"Ret10_hi\"] = df[\"Hi PRIOR\"].rolling(10).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "df[\"Ret25_hi\"] = df[\"Hi PRIOR\"].rolling(25).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "df[\"Ret60_hi\"] = df[\"Hi PRIOR\"].rolling(60).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "df[\"Ret120_hi\"] = df[\"Hi PRIOR\"].rolling(120).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "df[\"Ret240_hi\"] = df[\"Hi PRIOR\"].rolling(240).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "\n",
    "df[\"Ret10_Low\"] = df[\"Lo PRIOR\"].rolling(10).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "df[\"Ret25_Low\"] = df[\"Lo PRIOR\"].rolling(25).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "df[\"Ret60_Low\"] = df[\"Lo PRIOR\"].rolling(60).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "df[\"Ret120_Low\"] = df[\"Lo PRIOR\"].rolling(120).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "df[\"Ret240_Low\"] = df[\"Lo PRIOR\"].rolling(240).apply(lambda x: np.prod(1 + x / 100) - 1)\n",
    "\n",
    "df[\"Ret60\"] = df[\"Ret60_MOMi\"].shift(-60)\n",
    "df = df.dropna()\n",
    "df.tail(10)\n",
    "\n",
    "df = df.drop(\n",
    "    [\n",
    "        \"Lo PRIOR\",\n",
    "        \"PRIOR 2\",\n",
    "        \"PRIOR 3\",\n",
    "        \"PRIOR 4\",\n",
    "        \"PRIOR 5\",\n",
    "        \"PRIOR 6\",\n",
    "        \"PRIOR 7\",\n",
    "        \"PRIOR 8\",\n",
    "        \"PRIOR 9\",\n",
    "        \"Hi PRIOR\",\n",
    "        \"Mom\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ret</th>\n",
       "      <th>Ret10_MOMi</th>\n",
       "      <th>Ret25_MOMi</th>\n",
       "      <th>Ret60_MOMi</th>\n",
       "      <th>Ret120_MOMi</th>\n",
       "      <th>Ret240_MOMi</th>\n",
       "      <th>Ret10_hi</th>\n",
       "      <th>Ret25_hi</th>\n",
       "      <th>Ret60_hi</th>\n",
       "      <th>Ret120_hi</th>\n",
       "      <th>Ret240_hi</th>\n",
       "      <th>Ret10_Low</th>\n",
       "      <th>Ret25_Low</th>\n",
       "      <th>Ret60_Low</th>\n",
       "      <th>Ret120_Low</th>\n",
       "      <th>Ret240_Low</th>\n",
       "      <th>Ret60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1927-08-19</th>\n",
       "      <td>1.60</td>\n",
       "      <td>-0.007189</td>\n",
       "      <td>-0.011632</td>\n",
       "      <td>0.029566</td>\n",
       "      <td>0.201590</td>\n",
       "      <td>0.275852</td>\n",
       "      <td>-0.003897</td>\n",
       "      <td>0.010958</td>\n",
       "      <td>0.031462</td>\n",
       "      <td>0.181792</td>\n",
       "      <td>0.458303</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.021960</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>-0.021026</td>\n",
       "      <td>0.125174</td>\n",
       "      <td>0.102616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927-08-20</th>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.016077</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>0.191185</td>\n",
       "      <td>0.267548</td>\n",
       "      <td>-0.006644</td>\n",
       "      <td>0.027704</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.192865</td>\n",
       "      <td>0.458015</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>0.028920</td>\n",
       "      <td>0.013091</td>\n",
       "      <td>-0.002974</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>0.087730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927-08-22</th>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.008596</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.033884</td>\n",
       "      <td>0.216675</td>\n",
       "      <td>0.279747</td>\n",
       "      <td>-0.002775</td>\n",
       "      <td>0.025256</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>0.209346</td>\n",
       "      <td>0.459903</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>0.021349</td>\n",
       "      <td>0.018498</td>\n",
       "      <td>-0.010311</td>\n",
       "      <td>0.123046</td>\n",
       "      <td>0.081898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927-08-23</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.033152</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>0.038926</td>\n",
       "      <td>0.213431</td>\n",
       "      <td>0.280381</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.018638</td>\n",
       "      <td>0.056751</td>\n",
       "      <td>0.207897</td>\n",
       "      <td>0.459320</td>\n",
       "      <td>-0.001583</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.015219</td>\n",
       "      <td>-0.008810</td>\n",
       "      <td>0.122026</td>\n",
       "      <td>0.040216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927-08-24</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.061988</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.066728</td>\n",
       "      <td>0.225576</td>\n",
       "      <td>0.314510</td>\n",
       "      <td>0.070620</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>0.086507</td>\n",
       "      <td>0.208018</td>\n",
       "      <td>0.470046</td>\n",
       "      <td>0.007666</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.016347</td>\n",
       "      <td>-0.018610</td>\n",
       "      <td>0.101036</td>\n",
       "      <td>0.036711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Ret  Ret10_MOMi  Ret25_MOMi  Ret60_MOMi  Ret120_MOMi  \\\n",
       "1927-08-19  1.60   -0.007189   -0.011632    0.029566     0.201590   \n",
       "1927-08-20  0.74   -0.016077   -0.002022    0.028443     0.191185   \n",
       "1927-08-22  0.71   -0.008596    0.002957    0.033884     0.216675   \n",
       "1927-08-23  0.97    0.033152    0.008149    0.038926     0.213431   \n",
       "1927-08-24  0.91    0.061988    0.007949    0.066728     0.225576   \n",
       "\n",
       "            Ret240_MOMi  Ret10_hi  Ret25_hi  Ret60_hi  Ret120_hi  Ret240_hi  \\\n",
       "1927-08-19     0.275852 -0.003897  0.010958  0.031462   0.181792   0.458303   \n",
       "1927-08-20     0.267548 -0.006644  0.027704  0.043832   0.192865   0.458015   \n",
       "1927-08-22     0.279747 -0.002775  0.025256  0.054955   0.209346   0.459903   \n",
       "1927-08-23     0.280381  0.031562  0.018638  0.056751   0.207897   0.459320   \n",
       "1927-08-24     0.314510  0.070620  0.015491  0.086507   0.208018   0.470046   \n",
       "\n",
       "            Ret10_Low  Ret25_Low  Ret60_Low  Ret120_Low  Ret240_Low     Ret60  \n",
       "1927-08-19   0.003376   0.021960  -0.000112   -0.021026    0.125174  0.102616  \n",
       "1927-08-20   0.009704   0.028920   0.013091   -0.002974    0.132384  0.087730  \n",
       "1927-08-22   0.005975   0.021349   0.018498   -0.010311    0.123046  0.081898  \n",
       "1927-08-23  -0.001583   0.009427   0.015219   -0.008810    0.122026  0.040216  \n",
       "1927-08-24   0.007666   0.006483   0.016347   -0.018610    0.101036  0.036711  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Train-Test Samples and Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ret</th>\n",
       "      <th>Ret10_MOMi</th>\n",
       "      <th>Ret25_MOMi</th>\n",
       "      <th>Ret60_MOMi</th>\n",
       "      <th>Ret120_MOMi</th>\n",
       "      <th>Ret240_MOMi</th>\n",
       "      <th>Ret10_hi</th>\n",
       "      <th>Ret25_hi</th>\n",
       "      <th>Ret60_hi</th>\n",
       "      <th>Ret120_hi</th>\n",
       "      <th>Ret240_hi</th>\n",
       "      <th>Ret10_Low</th>\n",
       "      <th>Ret25_Low</th>\n",
       "      <th>Ret60_Low</th>\n",
       "      <th>Ret120_Low</th>\n",
       "      <th>Ret240_Low</th>\n",
       "      <th>Ret60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1927-08-19</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-0.007189</td>\n",
       "      <td>-0.011632</td>\n",
       "      <td>0.029566</td>\n",
       "      <td>0.201590</td>\n",
       "      <td>0.275852</td>\n",
       "      <td>-0.003897</td>\n",
       "      <td>0.010958</td>\n",
       "      <td>0.031462</td>\n",
       "      <td>0.181792</td>\n",
       "      <td>0.458303</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.021960</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>-0.021026</td>\n",
       "      <td>0.125174</td>\n",
       "      <td>0.102616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1927-08-20</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.016077</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>0.191185</td>\n",
       "      <td>0.267548</td>\n",
       "      <td>-0.006644</td>\n",
       "      <td>0.027704</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.192865</td>\n",
       "      <td>0.458015</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>0.028920</td>\n",
       "      <td>0.013091</td>\n",
       "      <td>-0.002974</td>\n",
       "      <td>0.132384</td>\n",
       "      <td>0.087730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1927-08-22</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.008596</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.033884</td>\n",
       "      <td>0.216675</td>\n",
       "      <td>0.279747</td>\n",
       "      <td>-0.002775</td>\n",
       "      <td>0.025256</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>0.209346</td>\n",
       "      <td>0.459903</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>0.021349</td>\n",
       "      <td>0.018498</td>\n",
       "      <td>-0.010311</td>\n",
       "      <td>0.123046</td>\n",
       "      <td>0.081898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1927-08-23</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.033152</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>0.038926</td>\n",
       "      <td>0.213431</td>\n",
       "      <td>0.280381</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.018638</td>\n",
       "      <td>0.056751</td>\n",
       "      <td>0.207897</td>\n",
       "      <td>0.459320</td>\n",
       "      <td>-0.001583</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.015219</td>\n",
       "      <td>-0.008810</td>\n",
       "      <td>0.122026</td>\n",
       "      <td>0.040216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1927-08-24</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.061988</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.066728</td>\n",
       "      <td>0.225576</td>\n",
       "      <td>0.314510</td>\n",
       "      <td>0.070620</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>0.086507</td>\n",
       "      <td>0.208018</td>\n",
       "      <td>0.470046</td>\n",
       "      <td>0.007666</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.016347</td>\n",
       "      <td>-0.018610</td>\n",
       "      <td>0.101036</td>\n",
       "      <td>0.036711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Ret  Ret10_MOMi  Ret25_MOMi  Ret60_MOMi  Ret120_MOMi  \\\n",
       "0 1927-08-19  1.60   -0.007189   -0.011632    0.029566     0.201590   \n",
       "1 1927-08-20  0.74   -0.016077   -0.002022    0.028443     0.191185   \n",
       "2 1927-08-22  0.71   -0.008596    0.002957    0.033884     0.216675   \n",
       "3 1927-08-23  0.97    0.033152    0.008149    0.038926     0.213431   \n",
       "4 1927-08-24  0.91    0.061988    0.007949    0.066728     0.225576   \n",
       "\n",
       "   Ret240_MOMi  Ret10_hi  Ret25_hi  Ret60_hi  Ret120_hi  Ret240_hi  Ret10_Low  \\\n",
       "0     0.275852 -0.003897  0.010958  0.031462   0.181792   0.458303   0.003376   \n",
       "1     0.267548 -0.006644  0.027704  0.043832   0.192865   0.458015   0.009704   \n",
       "2     0.279747 -0.002775  0.025256  0.054955   0.209346   0.459903   0.005975   \n",
       "3     0.280381  0.031562  0.018638  0.056751   0.207897   0.459320  -0.001583   \n",
       "4     0.314510  0.070620  0.015491  0.086507   0.208018   0.470046   0.007666   \n",
       "\n",
       "   Ret25_Low  Ret60_Low  Ret120_Low  Ret240_Low     Ret60  \n",
       "0   0.021960  -0.000112   -0.021026    0.125174  0.102616  \n",
       "1   0.028920   0.013091   -0.002974    0.132384  0.087730  \n",
       "2   0.021349   0.018498   -0.010311    0.123046  0.081898  \n",
       "3   0.009427   0.015219   -0.008810    0.122026  0.040216  \n",
       "4   0.006483   0.016347   -0.018610    0.101036  0.036711  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={\"index\": \"Date\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ret</th>\n",
       "      <th>Ret10_MOMi</th>\n",
       "      <th>Ret25_MOMi</th>\n",
       "      <th>Ret60_MOMi</th>\n",
       "      <th>Ret120_MOMi</th>\n",
       "      <th>Ret240_MOMi</th>\n",
       "      <th>Ret10_hi</th>\n",
       "      <th>Ret25_hi</th>\n",
       "      <th>Ret60_hi</th>\n",
       "      <th>Ret120_hi</th>\n",
       "      <th>Ret240_hi</th>\n",
       "      <th>Ret10_Low</th>\n",
       "      <th>Ret25_Low</th>\n",
       "      <th>Ret60_Low</th>\n",
       "      <th>Ret120_Low</th>\n",
       "      <th>Ret240_Low</th>\n",
       "      <th>Ret60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25475</th>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>-4.21</td>\n",
       "      <td>-0.035453</td>\n",
       "      <td>0.063937</td>\n",
       "      <td>-0.114656</td>\n",
       "      <td>-0.021273</td>\n",
       "      <td>0.182380</td>\n",
       "      <td>-0.034336</td>\n",
       "      <td>0.038463</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.112082</td>\n",
       "      <td>0.463052</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>-0.023261</td>\n",
       "      <td>0.124712</td>\n",
       "      <td>0.119166</td>\n",
       "      <td>0.183476</td>\n",
       "      <td>0.117438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25476</th>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.026478</td>\n",
       "      <td>0.078585</td>\n",
       "      <td>-0.125749</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>0.172962</td>\n",
       "      <td>-0.022781</td>\n",
       "      <td>0.041748</td>\n",
       "      <td>-0.018133</td>\n",
       "      <td>0.147941</td>\n",
       "      <td>0.483963</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>-0.033350</td>\n",
       "      <td>0.114849</td>\n",
       "      <td>0.112311</td>\n",
       "      <td>0.210427</td>\n",
       "      <td>0.059617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25477</th>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-0.056702</td>\n",
       "      <td>0.062432</td>\n",
       "      <td>-0.133705</td>\n",
       "      <td>-0.043668</td>\n",
       "      <td>0.150308</td>\n",
       "      <td>-0.101268</td>\n",
       "      <td>-0.013252</td>\n",
       "      <td>-0.069597</td>\n",
       "      <td>0.046629</td>\n",
       "      <td>0.397170</td>\n",
       "      <td>-0.046576</td>\n",
       "      <td>-0.069687</td>\n",
       "      <td>0.067058</td>\n",
       "      <td>0.079807</td>\n",
       "      <td>0.163062</td>\n",
       "      <td>0.098866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25478</th>\n",
       "      <td>2024-09-04</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.048273</td>\n",
       "      <td>0.106131</td>\n",
       "      <td>-0.140717</td>\n",
       "      <td>-0.033861</td>\n",
       "      <td>0.162805</td>\n",
       "      <td>-0.093159</td>\n",
       "      <td>0.019845</td>\n",
       "      <td>-0.073135</td>\n",
       "      <td>0.047156</td>\n",
       "      <td>0.412210</td>\n",
       "      <td>-0.046576</td>\n",
       "      <td>-0.076586</td>\n",
       "      <td>0.071820</td>\n",
       "      <td>0.069334</td>\n",
       "      <td>0.162827</td>\n",
       "      <td>0.075027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25479</th>\n",
       "      <td>2024-09-05</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.049032</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>-0.157206</td>\n",
       "      <td>-0.045109</td>\n",
       "      <td>0.168755</td>\n",
       "      <td>-0.101854</td>\n",
       "      <td>-0.034501</td>\n",
       "      <td>-0.084556</td>\n",
       "      <td>0.059955</td>\n",
       "      <td>0.449385</td>\n",
       "      <td>-0.054984</td>\n",
       "      <td>-0.080997</td>\n",
       "      <td>0.079483</td>\n",
       "      <td>0.095512</td>\n",
       "      <td>0.187280</td>\n",
       "      <td>0.080071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   Ret  Ret10_MOMi  Ret25_MOMi  Ret60_MOMi  Ret120_MOMi  \\\n",
       "25475 2024-08-29 -4.21   -0.035453    0.063937   -0.114656    -0.021273   \n",
       "25476 2024-08-30  0.88   -0.026478    0.078585   -0.125749     0.016932   \n",
       "25477 2024-09-03 -2.00   -0.056702    0.062432   -0.133705    -0.043668   \n",
       "25478 2024-09-04  0.49   -0.048273    0.106131   -0.140717    -0.033861   \n",
       "25479 2024-09-05  0.18   -0.049032    0.051948   -0.157206    -0.045109   \n",
       "\n",
       "       Ret240_MOMi  Ret10_hi  Ret25_hi  Ret60_hi  Ret120_hi  Ret240_hi  \\\n",
       "25475     0.182380 -0.034336  0.038463  0.002863   0.112082   0.463052   \n",
       "25476     0.172962 -0.022781  0.041748 -0.018133   0.147941   0.483963   \n",
       "25477     0.150308 -0.101268 -0.013252 -0.069597   0.046629   0.397170   \n",
       "25478     0.162805 -0.093159  0.019845 -0.073135   0.047156   0.412210   \n",
       "25479     0.168755 -0.101854 -0.034501 -0.084556   0.059955   0.449385   \n",
       "\n",
       "       Ret10_Low  Ret25_Low  Ret60_Low  Ret120_Low  Ret240_Low     Ret60  \n",
       "25475   0.001078  -0.023261   0.124712    0.119166    0.183476  0.117438  \n",
       "25476   0.003772  -0.033350   0.114849    0.112311    0.210427  0.059617  \n",
       "25477  -0.046576  -0.069687   0.067058    0.079807    0.163062  0.098866  \n",
       "25478  -0.046576  -0.076586   0.071820    0.069334    0.162827  0.075027  \n",
       "25479  -0.054984  -0.080997   0.079483    0.095512    0.187280  0.080071  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "ts = int(0.4 * len(df))\n",
    "split_time = len(df) - ts\n",
    "test_time = df.iloc[split_time:, 0:1].values\n",
    "Ret_vector = df.iloc[split_time:, 1:2].values\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15288, 15) (10192, 15) (15288,) (10192,)\n"
     ]
    }
   ],
   "source": [
    "Xdf, ydf = df.iloc[:, 2:-1], df.iloc[:, -1]\n",
    "X = Xdf.astype(\"float32\")\n",
    "y = ydf.astype(\"float32\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=ts, shuffle=False\n",
    ")\n",
    "n_features = X_train.shape[1]\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_input = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler_input.fit(X_train)\n",
    "X_train = scaler_input.transform(X_train)\n",
    "X_test = scaler_input.transform(X_test)\n",
    "\n",
    "mean_ret = np.mean(y_train)  # Useful to compute the performance = R2\n",
    "\n",
    "scaler_output = MinMaxScaler(feature_range=(-1, 1))\n",
    "y_train = y_train.values.reshape(len(y_train), 1)\n",
    "y_test = y_test.values.reshape(len(y_test), 1)\n",
    "scaler_output.fit(y_train)\n",
    "y_train = scaler_output.transform(y_train)\n",
    "y_test = scaler_output.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP Model and Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Activation function** - The rectified linear unit (**ReLU**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Hiden layers and units within layers** - A total of 3 hidden layers, each layer will have 50, 30, and 10 unts respectively in order from the input layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Output layer** - A fully connected layer for the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Learning rate** - A learning rate of $10^{-5}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Optimizer** - The Adam optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Loss function** - Different from the linear regression case, we select a loss functtion based on the **mean absolute error (MAE)**:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    L(y, \\hat{y}) = \\frac{1}{n}\\sum_{i=1}^n |y_i - \\hat{y}_i| \n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(12345)\n",
    "\n",
    "act_fun = \"relu\"  # Activation function\n",
    "hp_units = 50  # Units in the first hidden layer\n",
    "hp_units_2 = 30  # Units in the second hidden layer\n",
    "hp_units_3 = 10  # Units in the third hidden layer\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=hp_units, activation=act_fun))\n",
    "model.add(tf.keras.layers.Dense(units=hp_units_2, activation=act_fun))\n",
    "model.add(tf.keras.layers.Dense(units=hp_units_3, activation=act_fun))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "hp_lr = 1e-5\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=hp_lr)\n",
    "model.compile(optimizer=adam, loss=\"mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have defined our model, we can train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "478/478 - 2s - 5ms/step - loss: 0.1380\n",
      "Epoch 2/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1308\n",
      "Epoch 3/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1283\n",
      "Epoch 4/30\n",
      "478/478 - 1s - 2ms/step - loss: 0.1274\n",
      "Epoch 5/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1269\n",
      "Epoch 6/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1265\n",
      "Epoch 7/30\n",
      "478/478 - 1s - 2ms/step - loss: 0.1262\n",
      "Epoch 8/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1259\n",
      "Epoch 9/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1256\n",
      "Epoch 10/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1254\n",
      "Epoch 11/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1251\n",
      "Epoch 12/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1249\n",
      "Epoch 13/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1247\n",
      "Epoch 14/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1245\n",
      "Epoch 15/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1243\n",
      "Epoch 16/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1240\n",
      "Epoch 17/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1238\n",
      "Epoch 18/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1235\n",
      "Epoch 19/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1232\n",
      "Epoch 20/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1229\n",
      "Epoch 21/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1226\n",
      "Epoch 22/30\n",
      "478/478 - 1s - 2ms/step - loss: 0.1224\n",
      "Epoch 23/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1223\n",
      "Epoch 24/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1221\n",
      "Epoch 25/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1220\n",
      "Epoch 26/30\n",
      "478/478 - 1s - 2ms/step - loss: 0.1218\n",
      "Epoch 27/30\n",
      "478/478 - 1s - 2ms/step - loss: 0.1217\n",
      "Epoch 28/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1216\n",
      "Epoch 29/30\n",
      "478/478 - 1s - 2ms/step - loss: 0.1214\n",
      "Epoch 30/30\n",
      "478/478 - 1s - 1ms/step - loss: 0.1213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2e6cf79eea0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,530</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m1,530\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m310\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,955</span> (31.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,955\u001b[0m (31.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,651</span> (10.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,651\u001b[0m (10.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,304</span> (20.72 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m5,304\u001b[0m (20.72 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first layer of the model,  there are 800 parameters. These are equal to the number of units in the layer (50) times the number of different inputs (15)-because there would be a weight associated with each input and unit in the layer-plus the bias terms $b$ for each unit (50). Thus, $15 \\times 50 + 50 = 800$.\n",
    "\n",
    "Where does the number of $1530$ parameters from the second layer come from?\n",
    "This is equal to the number of \"inputs\" to this layer (which is essentially the number of units in the previous layer (50) times the number of units in the layer (30) plus the bias term for each unit (30). Thus, $50 \\times 30 + 30 = 1530$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation and Early stopping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **How many epochs should we use when training our model?** - The choice of the number of epochs that we have used (30) is discretionary. We're going to change this by including **Early stopping** in our training. Meaning, intructing Keras to stop model training when some condition is met. This is done via the **callback API** in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **When should we stop training** - Once after each epoch of the training process, we will check if (and how much) the loss function in the validation set decreases. We'll also define a parameter, **patience**, that indicates the number of epochs with no improvement in the validation set that we tolerate before Early stopping training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the characteristics of Early stopping:\n",
    "\n",
    "1. **The quantity/set to monitor**: in our case the validation set loss function.\n",
    "\n",
    "2. **The 'mode'**: by setting this to 'min' we ensure training will stop when the quantity set in (1) has stop decreasing.\n",
    "\n",
    "3. **Patience**: we will allow for 10 epochs with no improvement in minimizing the loss function of the validation set before we stop training. \n",
    "\n",
    "4. **restore_best_weights**: due to iteration process, it may be the case that the last iteration before stopping training does not yield the model weights that acheieve the lowest loss function in validation. By settting this option to 'True' we ensure that we keep the weights that achieved the best loss function value (the lowest) in validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
