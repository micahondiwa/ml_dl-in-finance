{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron: Market  Timing of APPL stock with Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Implement Keras Tuner in mlp model for stock timing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "df = yf.download(\"AAPL\", start=\"1980-01-01\", end=\"2022-04-11\")\n",
    "\n",
    "df[\"Ret\"] = df[\"Adj Close\"].pct_change()\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "name = \"Ret\"\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inputs and outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Ret25_i\"] = df[name].rolling(25).apply(lambda x: 100 * (np.prod(1 + x / 100) - 1))\n",
    "df[\"Ret60_i\"] = df[name].rolling(60).apply(lambda x: 100 * (np.prod(1 + x / 100) - 1))\n",
    "df[\"Ret90_i\"] = df[name].rolling(90).apply(lambda x: 100 * (np.prod(1 + x / 100) - 1))\n",
    "df[\"Ret120_i\"] = df[name].rolling(120).apply(lambda x: 100 * (np.prod(1 + x / 100) - 1))\n",
    "df[\"Ret240_i\"] = df[name].rolling(240).apply(lambda x: 100 * (np.prod(1 + x / 100) - 1))\n",
    "\n",
    "del df[\"Open\"]\n",
    "del df[\"Close\"]\n",
    "del df[\"High\"]\n",
    "del df[\"Low\"]\n",
    "del df[\"Volume\"]\n",
    "del df[\"Adj Close\"]\n",
    "\n",
    "df = df.dropna()\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the output: Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output is actually a continuous variable containing the returns of AAPL stock for some future time span.\n",
    "- The model will aim to predict the return of AAPL stock over the next 25 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Ret25\"] = df[\"Ret25_i\"].shift(-25)\n",
    "df = df.dropna()\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train-Test samples and Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = int(0.4 * len(df))  # Number of observations in the test sample\n",
    "split_time = len(df) - ts  # From this data we are in the test sample\n",
    "test_time = df.iloc[split_time:, 0:1].values  # Keep the test sample dates\n",
    "Ret_vector = df.iloc[split_time:, 1:2].values\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xdf, ydf = df.iloc[:, 2:-1], df.iloc[:, -1]\n",
    "X = Xdf.astype(\"float32\")\n",
    "y = ydf.astype(\"float32\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=ts, shuffle=False\n",
    ")  # It is important to keep \"shuffle=False\"\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Model and Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from keras_tuner import HyperModel\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropout: we are letting the tuner choose between a value for dropout of 0.2 or 0.3.\n",
    "\n",
    "- Number of layers in the model: in this case, we will let the tuner choose between 1 and 5 hidden layers in the model. We do this using the hp.Int() method.\n",
    "\n",
    "- Number of units in each hidden layer: the tuner will choose between 1 (min_value) and 25 (max_value) units in each layer, with a step size of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(1234)\n",
    "val_split = 0.2\n",
    "\n",
    "\n",
    "class MLP_model(HyperModel):\n",
    "    def build(self, hp):\n",
    "        # We define a constant activation function of ReLU form. We will not be tuning the activation functions\n",
    "        act_fun = \"relu\"\n",
    "\n",
    "        # We do ask the Keras Tuner to choose whether is best to have a dropout rate after each hidden layer of 0.2 or 0.3\n",
    "        n_dropout = hp.Choice(\"n_dropout\", values=[0.20, 0.30])\n",
    "\n",
    "        model = tf.keras.models.Sequential()\n",
    "\n",
    "        # Now, we will use a loop to let the tuner choose the number of layers that is best for the model between 1 and 5\n",
    "        for i in range(1, hp.Int(\"num_layers\", 1, 5)):\n",
    "            # Within this loop, we will also ask the tuner to decide the optimal number of units that each of the selected layer should have.\n",
    "            model.add(\n",
    "                tf.keras.layers.Dense(\n",
    "                    units=hp.Int(\n",
    "                        \"units_dense_\" + str(i), min_value=1, max_value=25, step=5\n",
    "                    ),\n",
    "                    activation=act_fun,\n",
    "                )\n",
    "            )\n",
    "            model.add(tf.keras.layers.Dropout(n_dropout))\n",
    "\n",
    "        model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "        # As was the case with the activation function, there is no tuning on the learning rate, nor the optimizer, although we could easily incorporate it.\n",
    "        hp_lr = 1e-5\n",
    "        adam = tf.keras.optimizers.Adam(learning_rate=hp_lr)\n",
    "        model.compile(optimizer=adam, loss=\"mean_absolute_error\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hypermodel: we have already defined our hypermodel: MLP_model()\n",
    "\n",
    "- Objective: what is the objective function to optimize? In this case we will minimize the loss function in the validation set.\n",
    "\n",
    "- Other parameters: these include whether we overwrite results, fixing the random seed, or storage of results (convenient for large complex models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we clear the session just to make sure our seeds are correctly working and replicability is achieved\n",
    "K.clear_session()\n",
    "\n",
    "# Then, we call the model and perform the tuning:\n",
    "hypermodel = MLP_model()\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel,\n",
    "    objective=kt.Objective(\"val_loss\", direction=\"min\"),\n",
    "    overwrite=True,\n",
    "    max_epochs=30,\n",
    "    seed=1234,\n",
    "    directory=os.path.normpath(\"C:/\"),\n",
    ")\n",
    "\n",
    "# Let's run the tuner! (Warning: this could take time)\n",
    "tuner.search(X_train, y_train, validation_split=val_split)\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", mode=\"min\", verbose=1, patience=20, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# fit the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    verbose=2,\n",
    "    callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Financial performance of the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame(\n",
    "    {\n",
    "        \"Date\": test_time.flatten(),\n",
    "        \"Pred\": y_pred.flatten(),\n",
    "        \"Ret\": (Ret_vector.flatten()),\n",
    "    }\n",
    ")\n",
    "df_predictions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.Date = pd.to_datetime(df_predictions.Date, format=\"%YYYY-%mm-%dd\")\n",
    "df = df_predictions\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategies:\n",
    "- Buy and hold: simply buys the stock at the beginning of the test period and holds it until the end.\n",
    "\n",
    "- Long-only: this strategy either goes long in the stock (if the predicted 25-day return is positive) or goes to cash (with a 0% return associated).\n",
    "\n",
    "- Long/Short this strategy goes long (short) in the stock when the 25-day ahead return predicted by the model is positive (negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Positions\"] = np.where(df[\"Pred\"] > 0, 1, -1)\n",
    "df[\"Strat_ret\"] = df[\"Positions\"].shift(1) * df[\"Ret\"]\n",
    "df[\"Positions_L\"] = df[\"Positions\"].shift(1)\n",
    "df[\"Positions_L\"][df[\"Positions_L\"] == -1] = 0\n",
    "df[\"Strat_ret_L\"] = df[\"Positions_L\"] * df[\"Ret\"]\n",
    "df[\"CumRet\"] = df[\"Strat_ret\"].expanding().apply(lambda x: np.prod(1 + x) - 1)\n",
    "df[\"CumRet_L\"] = df[\"Strat_ret_L\"].expanding().apply(lambda x: np.prod(1 + x) - 1)\n",
    "df[\"bhRet\"] = df[\"Ret\"].expanding().apply(lambda x: np.prod(1 + x) - 1)\n",
    "\n",
    "Final_Return_L = np.prod(1 + df[\"Strat_ret_L\"]) - 1\n",
    "Final_Return = np.prod(1 + df[\"Strat_ret\"]) - 1\n",
    "Buy_Return = np.prod(1 + df[\"Ret\"]) - 1\n",
    "\n",
    "print(\"Strat Return Long Only =\", Final_Return_L * 100, \"%\")\n",
    "print(\"Strat Return =\", Final_Return * 100, \"%\")\n",
    "print(\"Buy and Hold Return =\", Buy_Return * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = plt.gca()\n",
    "df.plot(x=\"Date\", y=\"bhRet\", label=\"Buy&Hold\", ax=ax)\n",
    "df.plot(x=\"Date\", y=\"CumRet_L\", label=\"Strat Only Long\", ax=ax)\n",
    "df.plot(x=\"Date\", y=\"CumRet\", label=\"Strat Long/Short\", ax=ax)\n",
    "plt.xlabel(\"date\")\n",
    "plt.ylabel(\"Cumulative Returns\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
